import feedparser
import urllib.parse
from groq import Groq
import time
import os
import json
from datetime import datetime
from email.utils import parsedate_to_datetime
from jinja2 import Environment, FileSystemLoader
from zoneinfo import ZoneInfo

# --- KONFIGURACE ---
# Tohle funguje univerz√°lnƒõ: doma to bere z .env, na GitHubu ze Secrets
API_KEY = os.getenv("GROQ_API_KEY")
DB_FILE = "database.json"
OUTPUT_FILE = "index.html"
TEMPLATE_FILE = "template.html"
DELAY_SECONDS = 2.0 

client = Groq(api_key=API_KEY)

# --- PR√ÅCE S DATAB√ÅZ√ç ---

def load_database():
    """Naƒçte existuj√≠c√≠ ƒçl√°nky ze souboru, aby se nep≈ôemaz√°valy."""
    if not os.path.exists(DB_FILE):
        return []
    try:
        with open(DB_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            # Reset tagu 'is_new' pro star√© ƒçl√°nky - p≈ôi nov√©m bƒõhu u≈æ nejsou nov√©
            for article in data:
                article['is_new'] = False 
            return data
    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi naƒç√≠t√°n√≠ DB: {e}, zakl√°d√°m novou.")
        return []

def save_database(data):
    """Ulo≈æ√≠ aktu√°ln√≠ stav do JSON"""
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def get_existing_links(data):
    """Vr√°t√≠ set v≈°ech URL, kter√© u≈æ m√°me, pro rychlou kontrolu duplicit"""
    return {item['link'] for item in data}

def parse_rss_date(entry):
    """Vyt√°hne datum z RSS nebo pou≈æije aktu√°ln√≠"""
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        # P≈ôevedeme struct_time na datetime
        return datetime(*entry.published_parsed[:6]).isoformat()
    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
        return datetime(*entry.updated_parsed[:6]).isoformat()
    else:
        # Fallback na teƒè
        return datetime.now().isoformat()

def format_date_display(iso_date):
    """P≈ôevede ISO string na hezk√Ω ƒçesk√Ω form√°t"""
    try:
        dt = datetime.fromisoformat(iso_date)
        return dt.strftime("%d. %m. %Y %H:%M")
    except:
        return iso_date

# --- VR√ÅTN√ù (Python Filtr) ---
def is_worth_checking(title):
    title_lower = title.lower()
    stop_words = [
        "vra≈æda", "zabil", "zem≈ôel", "√∫mrt√≠", "nehoda", "trag√©die", "po≈æ√°r", 
        "soud", "vƒõzen√≠", "policie", "krimi", "zlodƒõj", "podvod", 
        "babi≈°", "fiala", "okamura", "pavel", "snƒõmovna", "vl√°da", "volby",
        "v√°lka", "rusko", "ukrajina", "izrael", "gaza", "√∫tok", "zbranƒõ",
        "recenze", "koment√°≈ô", "glosa", "sport", "hokej", "fotbal", "liga"
    ]
    for word in stop_words:
        if word in title_lower:
            return False
    return True

# --- AI ANAL√ùZA ---
def analyze_article_with_groq(title, description, link):
    system_prompt = """
    Jsi editor seri√≥zn√≠ho pozitivn√≠ho webu. 
    Analyzuj zpr√°vu na z√°kladƒõ titulku a perexu.
    
    KRIT√âRIA:
    1. Hled√°me POUZE: Vƒõdeck√© objevy, Technologick√© inovace, Byznysov√© √∫spƒõchy, Medic√≠nsk√© pr≈Ølomy, Dokonƒçen√© projekty, Pomoc lidem.
    2. IGNORUJ: Politiku, Krimi, Nehody, Bulv√°r, Sportovn√≠ v√Ωsledky.
    
    POKUD ZPR√ÅVA NEN√ç POZITIVN√ç:
    Odpovƒõz pouze slovem: SKIP
    
    POKUD JE POZITIVN√ç:
    Odpovƒõz v tomto form√°tu:
    KATEGORIE: [Vyber jednu: Vƒõda / Technologie / Medic√≠na / Byznys / Spoleƒçnost]
    TITULEK: [P≈ôeformuluj na √∫dern√Ω titulek, max 8 slov]
    SHRNUT√ç: [Napi≈° kvalitn√≠ shrnut√≠ na 30-50 slov.]
    """

    clean_desc = description.replace("<br>", " ").replace("<p>", "")[:600]

    user_content = f"TITULEK: '{title}'\nPEREX: '{clean_desc}'\nODKAZ: {link}"

    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            model="llama-3.3-70b-versatile", 
            temperature=0.1, 
        )

        text = chat_completion.choices[0].message.content.strip()
        if "SKIP" in text:
            return None
        return text

    except Exception as e:
        print(f"‚ö†Ô∏è Chyba Groq: {e}")
        if "429" in str(e):
            time.sleep(30)
        return None

def parse_ai_result(text, original_link, timestamp):
    try:
        category = text.split("KATEGORIE:")[1].split("TITULEK:")[0].strip()
        title = text.split("TITULEK:")[1].split("SHRNUT√ç:")[0].strip()
        summary = text.split("SHRNUT√ç:")[1].strip()
        title = title.replace('"', '').replace("'", "")
        
        # Sjednot√≠me kategorie pro filtrov√°n√≠ (kdyby AI vym√Ω≈°lela)
        valid_cats = ["Vƒõda", "Technologie", "Medic√≠na", "Byznys", "Spoleƒçnost"]
        if category not in valid_cats:
            category = "Spoleƒçnost" # Default

        return {
            "category": category,
            "title": title,
            "summary": summary,
            "link": original_link,
            "timestamp": timestamp, # Ukl√°d√°me ISO form√°t pro t≈ô√≠dƒõn√≠
            "timestamp_display": format_date_display(timestamp), # Pro zobrazen√≠
            "is_new": True # Pr√°vƒõ p≈ôid√°no
        }
    except Exception as e:
        return None

def generate_html_from_template(articles):
    env = Environment(loader=FileSystemLoader('.'))
    template = env.get_template(TEMPLATE_FILE)
    
    # Z√≠sk√°me aktu√°ln√≠ ƒças v Praze
    cz_time = datetime.now(ZoneInfo("Europe/Prague")) # <--- ZMƒöNA
    
    output_html = template.render(
        articles=articles,
        last_update=cz_time.strftime("%d. %m. %Y %H:%M") # <--- ZMƒöNA (pou≈æijeme cz_time)
    )
    
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(output_html)
    print(f"\n‚úÖ Web vygenerov√°n: {os.path.abspath(OUTPUT_FILE)}")

# --- HLAVN√ç LOGIKA ---

base_query = '(site:e15.cz OR site:ceskenoviny.cz OR site:vtm.zive.cz OR site:irozhlas.cz OR site:cc.cz OR site:forbes.cz) AND (√∫spƒõch OR investice OR "nov√° tov√°rna" OR vyn√°lez OR startup OR vƒõdci OR l√©k) -krimi -soud'
encoded_query = urllib.parse.quote(base_query)
rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=cs&gl=CZ&ceid=CZ:cs"

# 1. Naƒçten√≠ datab√°ze
print("üìÇ Naƒç√≠t√°m lok√°ln√≠ datab√°zi...")
db_articles = load_database()
existing_links = get_existing_links(db_articles)
print(f"   M√°me v pamƒõti {len(db_articles)} star≈°√≠ch ƒçl√°nk≈Ø.")

print("üì° Stahuji RSS feed...")
feed = feedparser.parse(rss_url)
print(f"   Ve feedu je {len(feed.entries)} ƒçl√°nk≈Ø ke kontrole.")
print("-" * 50)

processed_count = 0
new_articles_count = 0

try:
    for entry in feed.entries:
        if new_articles_count >= 10: # Max 10 nov√Ωch na jeden bƒõh
            print("üéâ M√°me dost nov√Ωch zpr√°v.")
            break
        
        if processed_count >= 60: 
            print("üèÅ Pro≈°li jsme dostatek polo≈æek z feedu.")
            break

        link = entry.link
        original_title = entry.title
        
        # KONTROLA DUPLICIT
        if link in existing_links:
            # print(f"   (Zn√°m√©) {original_title[:30]}...") # Odkomentuj pro debug
            processed_count += 1
            continue # P≈ôeskakujeme, u≈æ to m√°me

        # PYTHON FILTR
        if not is_worth_checking(original_title):
            processed_count += 1
            continue 

        processed_count += 1
        
        # GROQ ANAL√ùZA (pouze pokud pro≈°lo v≈°emi filtry)
        if processed_count > 1:
            time.sleep(DELAY_SECONDS)

        print(f"[{processed_count}] Groq analyzuje NOV√â: {original_title[:40]}...")
        
        description = getattr(entry, 'summary', '') or getattr(entry, 'description', '') 
        timestamp = parse_rss_date(entry) # Z√≠sk√°n√≠ data

        result = analyze_article_with_groq(original_title, description, link)
        
        if result:
            print(f"   ‚úÖ BINGO! P≈ôid√°v√°m do DB.")
            parsed = parse_ai_result(result, link, timestamp)
            if parsed:
                db_articles.append(parsed)
                new_articles_count += 1
        else:
            print(f"   ‚ùå Odpad.")

except KeyboardInterrupt:
    print("\nüõë P≈ôeru≈°eno u≈æivatelem.")

finally:
    # 2. T≈ò√çDƒöN√ç (SORTING)
    # T≈ô√≠d√≠me takto: 
    #   1. Krit√©rium: is_new (True je vƒõt≈°√≠ ne≈æ False, tak≈æe True bude naho≈ôe)
    #   2. Krit√©rium: timestamp (nejnovƒõj≈°√≠ datum naho≈ôe)
    print("üîÑ T≈ô√≠d√≠m ƒçl√°nky (Nov√© > Star√©)...")
    db_articles.sort(key=lambda x: (x.get('is_new', False), x.get('timestamp', '')), reverse=True)

    # 3. ULO≈ΩEN√ç
    save_database(db_articles)

    # 4. GENEROW√ÅN√ç HTML

    generate_html_from_template(db_articles)
